摘要:
该教程是MVS领域专注于实用算法的实践手册,MVS算法是只依赖于图像,基于一些合理的假设(比如?)重建出真实精确的3d模型. 最重要的是场景固定.该教程将mvs问题转化成图像/几何约束优化问题.详细来说主要在两方面: 1.鲁棒实现图像一致性检测;2.有效的优化算法.
主要讲了这两因素在应用程序和工业中如何应用.本教程还描述了高级方法涉及到领域专业知识如:结构优化,以及接下来的挑战和未来的研究方向.

1简介

1.1 图像获取
  有序无序

1.2 相机投影模型
如简介所述，为了使重建效果更好，MVS算法需要额外的信息，尤其是每个图片对应的相机模型-它描述了如何将3D点投影到对应的2D空间,MVS算法常采用针孔相机模型，它的相机投影矩阵是3X4的矩阵[88],按比例定义的.这是通常用于拍摄静态照片的现成数码相机的模型。任何一个3X4的矩阵都可以分解成3x3的上三角矩阵K和3X4姿态矩阵的乘积[R|T].

![Alt text](./mvs_pic/formula1-1.png )

K --- 相机内参矩阵
(fx, fy): 垂直/水平焦距
(cx, cy): 主点
s       : 扭曲畸变

[R|T] --- 外参矩阵
R : 旋转参数
T : 平移参数

矩阵K是相机的内参矩阵，它是由相机的内参组成，垂直、水平焦点（光心）长度(f<sub>x</sub>, f<sub>y</sub>),主点（c<sub>x</sub>, c<sub>y</sub>）,畸变参数s。[R|T]矩阵为外参矩阵，R是相机的旋转矩阵，T是相机的平移矩阵。由于相机传感器的质量问题，人们很少估计相机投影矩阵的11个参数，一般假设 没有畸变即s = 0,传感器为方形即fx = fy，图像没被裁剪时主点在相机中心,因此普通针孔相机的相机参数由 焦距f,旋转矩阵R和平移矩阵T中7个参数组成;

![Alt text](./mvs_pic/1-4.jpg )

对于附加镜头成像效果不好或者广角相机（如图1.4左所示）,单纯的针孔相机模型不足以表示相机模型，通常要加上一个径向畸变.尤其是对高分辨率图像径向畸变是很重要的，因为微小的偏离将会涉及到边界的多个像素值.
径向畸变通常在进入MVS算法流程之前消除，如果径向畸变参数已经估算出来，可以通过重新采样对图像反畸变处理消除畸变,就像是通过理想镜头获取的无畸变图像（图1.4左下）。消除图像畸变可以简化MVS算法,计算时间更短。一些相机如手机相机或者专用硬件在图像获取之后进行去畸变处理.注意修正的广角图像需要重新采样及视野裁剪,为了避免这些问题mvs算法需要支持径向畸变及更复杂的相机模型，这增加额外的复杂度。
最后，滚动快门是特别复杂模型的另一原因，对视频处理应用很重要（见图1.4右）。 带有滚动快门的数字传感器暴光出每一排图像的时间略有不同。 这与全局快门形成鲜明对比，全局快门是将整个图像同时曝光。 滚动快门通常以更高的更高的传感器吞吐量，其相机模型更加复杂。 因此，在捕获图像时如果相机或场景在移动，图像的每一行捕获的场景略微不同。 如果相机或场景运动缓慢。w.r.t. 快门速度很快，滚动快门效果小到足以被忽略。 否则，相机投影模型需要融合快门效果[63]。

1.3 Structure from Motion
有许多关于 Structure from Motion 算法的文章，本章的目的也不是详细介绍该算发，接下来我们会讨论一些SFM算法的关键点以及它与MVS算法的关系。
SFM算法输入一系列图像，输出每张图像的相机参数和图像中3D点，通常被称为迹点, 迹点通常是重建3D点的空间坐标以及其在对应图像上的2D坐标.当下SFM算法的基本流程如图1.5所示：
#####计算每张图像的2D特征点
#####图像间2D特征点匹配
#####从匹配关系构建2D tracks
#####从2D tracks 解sfm 模型
#####bundle adjustment优化sfm模型

![Alt text](./mvs_pic/1-5.png )

SfM的初步工作主要集中在刚性场景的假设下二视图和三视图下的几何特征的构建上[88]。 Carlo Tomasi的视觉重建算法[182]是早期工作的雏形。 SfM的关键发展之一是在嘈杂的匹配中使用RANSAC [61]鲁棒的估计二视图和三视图之间的极线几何。

然后，成果集中在SfM算法的两个关键部分：1）从多个相机计算欧几里德重建（缩放），即估计摄像机参数和迹点的3D位置；2）构建更长的2D迹点， 20世纪末，SfM算法能够从大型结构化图像集稳健地获取计算模型，例如从图像序列或视频序列[62,152]。第一批SfM工业解决方案开始商业化应用，例如在电影编辑和特效领域[4]。

最初这些系统主要是为结构化图像集而设计的，即图像顺序非常重要，例如视频序列。 虽然一些MVS应用程序可以实现结构化顺序，例如，Google StreetView [81]或微软 Streetside [143]，许多最近的MVS应用程序也使用在不同时间、不同硬件获取的、无序的图像集，例如，航拍图像的3D地图[108,144,30]。 随着质量高速度快的特征检测器[87,135,57]和描述子[135,36,159,130,26]的发展，使SfM能够应用于非结构化数据集。 高质量的描述子使从不同拍摄姿态和照明构建更长质量更高的迹点成为可能。

解决大型非结构化照片SfM的最终要素是改善匹配阶段。 对于非结构化照片集，人们没有任何关于候选图像附近应该匹配的先验知识。 因此，每个图像必须与其他图像一一匹配，即计算上非常昂贵。 有效的索引[146]结合高质量的描述子允许数百万的有效成对匹配的图像。 简化连通图的迹点[172]和并行化[25,64]进一步导致业界使用的t state-of the-art 的SfM流程，例如，微软的photosynth [16]和谷歌的photo tours[15]（见图1.6）。

![Alt text](./mvs_pic/1-6.png "Optional title")

1.4 Bundle Adjustment

 算法: RANSAC 从有噪声的匹配中计算极线几何
1> 多相机的欧几里得重建---估算相机参数和tracks 3D点
2> 构建longer tracks

尽管BA算法不是SFM算法的一部分，优化SFM算法的初始模型是常见步骤，给一系列相机参数{Pi}和迹点s{Mj,{mji}}， Mj代表轨迹点的3D坐标，mij代表在第i个摄像机的投影2d图像坐标。BA算法最小化以下非线性最小二乘误差

![Alt text](./mvs_pic/formula1-2.PNG "Optional title")

式中： v(j)：是点Mj可见的摄像机索引列表
pi（mj）：表示相机中3D点Mj在相机i及相机参数Pi的2D投影坐标,
E(P,M):通常以平方像素测量，但更常见度量是使用均方根误差或RMSE来表达估计精度，以像素为单位测量，定义如下：

![Alt text](./mvs_pic/formula1-3.PNG "Optional title")

其中N是（1.2）中剩余项数的和。BA算法之前的典型RMSE值大约为几个像素，而BA优化之后的值通常是亚像素。
BA框架支持将多个传感器与SfM目标相结合。 SfM融合GPS和IMU数据的一种方法是简单地添加单独项到式（1.2），惩罚偏差来自GPS和IMU信号的预测与相机模型Pi。

MVS算法对相机模型估计的准确性非常敏感。 原因是，出于效率目的，他们使用由相机模型定义的极线几何将2D问题匹配成一维匹配问题（更多细节参见第1.5节）。 如果重投影错误很大，则像素可能永远不会与其真实匹配相比，显着降低了MVS性能。 MVS对相机重投影误差的鲁棒性取决于主要是关于如何容忍匹配标准（即第2章中提出的照片一致性措施）是否错位。 通常，照片一致性度量的域Ω越大（参见式2.1），测量越稳健。 不幸的是，很大域也倾向于产生过度平滑的几何，所以有一个准确性和稳健性之间的妥协。

由于MVS对重投影错误非常敏感，因此BA算法通常是MVS的要求，目标是子像素重投影错误。 请注意，因为重投影错误是以像素为单位测量的，可以对输入图像进行下采样并重新缩放相机参数，直到重投影误差降至某个阈值以下。 这个只要下采样图像仍然包含，方法就会起作用足够的纹理和细节让MVS发挥作用[72]。

1.5 Multi-View Stereo
多视图立体视觉的起源可以追溯到人类立体视觉，并且是第一次尝试解决立体匹配问题，通过把它作为一个计算问题[139]。 直到今天，双视图立体算法一直是一个非常活跃非常成熟的研究领域[162]。多视图立体几何起源于对双视图立体几何的自然改进。 多视图立体几何不是从两个不同的视点捕获两张照片，而是在视点中间捕获更多的照片以增加稳健性，例如图像噪声或表面纹理[184,147]，最初是一种改进双视立体声的方法，如今演变成一种不同类型的问题。

虽然MVS与这种经典立体声具有相同的算法原理，MVS算法旨在处理图像更多变化的视点，例如围绕物体的图像集，并且还处理非常大量的图像，即使在数百万的订单。 MVS问题性质的差异最终会产生与经典不同的算法立体声对应物 作为一个例子，3D绘图的工业应用[108,144,30]，处理数百万张照片一次千米，有效地重建大都市区，国家，最终整个世界。

匹配图像中的像素是一个具有挑战性的问题独特的立体声或多视角立体声。 事实上，光流是另一回事计算机视觉领域非常活跃，解决了图像密集对应的问题[33]。 与MVS的主要区别在于光流通常是两个图像问题（类似于两个视图立体声），相机未校准，其主要应用是图像插值而不是3D重建。请注意，在MVS的情况下，摄像机参数是已知，求解场景的3D几何形状完全相同解决输入图像中的对应问题。 查看为什么，考虑属于3D场景几何的3D点（参见图1.7左）。 将3D点投影到可见摄像机组中建立投影坐标之间的唯一对应关系在每个图像上。给定图像中的像素，在其他像素中找到相应的像素图像需要两个成分：
在其他方面生成可能的像素候选的有效方法图片。
•衡量某个候选人是否正确的可能性的衡量标准比赛。

如果不知道相机的几何形状，通常情况就是如此在光流中，图像中的每个像素可以匹配另一图像中的任何其他像素。也就是说，对于每个像素，必须在另一个像素中进行2D搜索图片。但是，当相机参数已知时（和场景是刚性的），图像匹配问题从2D搜索简化进行一维搜索（见右图1.7）。图像中的像素生成a3D光线穿过像素和相机中心图片。另一个图像上的相应像素只能位于其上将光线投射到第二幅图像中。不同的多个摄像机看到的几何约束来自不同视点的相同3D场景被称为极线几何[88]。至于判断候选人匹配的可能性的措施，有一个关于如何建立所谓的照片一致性措施的大量文献估计两个像素（或像素组）的可能性在通信中。 MVS背景下的照片一致性测量在第2章中有更详细的介绍。

## chapter 2

N张输入图像和一个所有图像都可以看到的3D点p,任意一对图像I<sub>i</sub>和I<sub>j</sub>关于点p的图像一致性 表示如下:

![avatar](./mvs_pic/consistency_pic.png)

式中:
p: 3D点;
 πi(p): 点p在图像i中的投影;
Ω(x):点x附近的邻域;
Ii(x): 在区域Ω内的图像强度 
ρ(f, g):两个vector之间的相似性测量;

图像一致性可以通过ρ和Ω的选择来确定.

一些图像一致性不需要邻域Ω一些需要, 邻域的主要作用是确定一块场景的区域是唯一的与场景和视角无关.唯一性和不相关性在图像一致性中经常互斥,邻域越大,图像唯一性的可能就越大,与其它图像的越容易匹配,同时邻域越大,由于变形,深度限制和平滑吉和假设(例如:平面假设)越难维持照明和视口不相关.

MVS算法中, 定义邻域的简单方法是:用一个固定大小的正方形像素网格，当输入图像与正在重建的表面共享大致相同的像素分辨率时这种方法很有效, eg,使用 3x3或者5x5的像素大小, 在更复杂的场景,图像的分辨率不一致,场景位置不是均匀分布的, 调整邻域的大小非常困难, 尺寸需要成比例
相反，图像分辨率和视点分离与场景的距离成正比。 有些方法甚至会改变邻域的形状，其中一个特别成功的实例
视图相关域是通过将域Ω计算为投影以3D点p为中心的3D局部区块 [210, 74],其他方法显着增加图像的密度，
这可以实现更小的域大小，极端情况是使用视频[145]或光场[195,117]

该领域相关的 概念非常相近的是概念是图像一致性聚合[162]，其中包括
在空间上聚合照片一致性测量以增加其鲁棒性。当在没有域的情况下计算的度量一起使用时它是最有效的, 例如 差分平方和Sum of Square Differences (SSD)和 差分绝对值和 Sum of Absolute Differences (SAD)由于先进的聚合技术能在不需要平滑的情况下使用(详见2.1.8).

图像一致性的定义见式2.1, 点的图像一致性可以定义如下,通过对单个图像相关的所有图像对的图像一致性求平均

![avatar](./mvs_pic/consistency_pic.png)

及对所有图相对的图像一致性求平均.

![avatar](./mvs_pic/consistency_pic.png)

如上所述:图像一致性的定义要求所有图像包含给定点,就是说必须已知图像包含给定点.接下来描述一些常用的图像一致性测量方法,详细信息见[99], 通过比较f和g两个vector计算 图像一致性, f,g可以通过采样灰度图的矩形区域来获取如图2-1所示;

![avatar](./mvs_pic/consistency_pic.png)

对于彩色图像,操作如下:
1.计算图像一致性之前将彩色图转为灰度图
2.对rgb通道,每个通道单独计算图像一致性,求平均
3.将,每个通道的vector合并成大的vector

简要说明下对于有无纹理的表面不同的测量方式如图2-2, 图2-3表示随着点沿着对极线移动时的图像一致性曲线,

#### 2.1.1 Normalized Cross Correlation(归一化交叉相关性)

zero-mean NCC 是多视觉立体几何中最常用的一致性测量算法之一, 算法图像增益与偏差无关,并且与材质和光照无关条件下使用例如计算
收集的图像光照和材质相差很多的情况下使用,NCC算法的缺点是缺少表面纹理和重复纹理,计算精度高.计算公式如下

![avatar](./mvs_pic/consistency_pic.png)

f 均值 σ标准差 f

对于彩色图像,将所有颜色简单的集中到一个vector应用上述公式中的效果不佳,在复杂情况下例如均匀纹理表面,主要视觉线索通常是其表面的细微阴影和阴影效果我们想要
NCC捕捉每个颜色通道中细微的空间强度变化，比颜色的强度变化小得多渠道。通过简单的连接，NCC只需要捕获不同颜色通道的强度变化。更好的解决方案
是独立计算每个颜色通道的NCC并返回NCC平均得分。更复杂的方法是计算和单独减去每个颜色通道的平均强度（’f和G’），但将所有颜色通道作为单个向量连接在一起计算其方差时（σf和σg）。这允许NCC捕获
每个颜色通道中的空间强度变化，同时降低权重具有较小强度变化的颜色通道。

#### 2.1.2  Sum of Squared Differences(平方差求和) SSD

#### 2.1.3 Sum of Absolute Differences(差分绝对值)

#### 2.1.4 Census 统计方法

#### 2.1.5 Rank

#### 2.1.6 Mutual information 互信息

#### 2.1.7 interval comparison间隔对比

*** Photo-consistency normalization ***

以上方法中的图像一致性测量方法很少作为MVS方法的最后阶段应用；相反，经常通过非线性操作转化用于以下目的：i>不同的图像一致性值归一化到同样的范围区间；II>将原始的图像一致性转化到“几何似然”，归一化对参数优化同结合图像一致性计算一样重要，或者其他因素。典型的转换包括：指数函数、线性截断函数、平滑函数，如图2.5；归一化函数就像一个黑箱，将图像一致性值转化成几何似然测量值，i.e.描述了它可能是3D几何的概率范围。

![fig2.5](mvs_pic/fig2-5.PNG)

上图中三个对应的函数分别为：
1>.
2>.
3>.

以上三个归一化函数中，指数函数理论上来讲是最合理的，也是最常用的。如果是高斯噪声函数并且没有外点，对SSD来说是最佳的函数。然而纯高斯噪声是不现实的，这就是为什么通常会优先选用SAD而不是SSD方法。
当考虑到图形一致性的内外点噪声模型时，归一化函数的形状期望是sigmoid形状的，有两个平缓的变化，中间是相对倾斜的变化量。如图2.5所示。其中的原理是：陡坡被认为是区分内外点的阈值。例如SAD方法中，典型的内点误差小于5级（共255级），典型的外点值高于10级，一旦SAD值高于10级，无论是20还是30，都会对应一个很低的几何似然值，相同的NCC值低于1/1.414的都会被认为不够精确会被丢弃。

#### 2.1.8 Photo-consistency aggregation(集合/聚集)***

图像一致性是一种带噪声的测量方式，并且再用来计算3D几何之前需要滤波操作。滤波操作的独立于计算一致性时候的作用域，作用域可以看成是一个集合，滤波操作通常不需要作用域例如SAD,有时间限制的算法，以及局部优化方法代替全局优化方法例如图割算法。

#### 2.1.9 Photo-consistency representation()***

最基础的滤波操作就是在局部域求平均值，例如一个固定大小的方块。 SAD方法中

#### 2.1.10 Popular choice

## **chapter 3 基于图像一致性的三维重建**

基于第二章的图像一致性算法，本章将会详细介绍最近几年流行的多视角立体几何算法。区分MVS算法有许多因素，例如图像一致性函数，场景表达，可视化计算和初始化条件。因此提出一个单独的分类并不容易。本文将会依据输出的场景表示方法作为主要分类方式。因为它决定了应用的场景，有兴趣的读者可以参考[165]查看mvs算法的分类方法。
Fig3.1 表示4种常用的表示方法：深度图、点云、体素场、mesh面片，本章将会介绍每种重建算法的state-of-the-art 方法。点云重建方法的渲染方式是采用基于点的渲染技术[160,83],展示了一个完整的纹理渲染模型，但是点云模型仅仅是独立的带颜色的3D点；体素场常用于计算机视觉和计算机图形学表示3D平面，常将体素场当成距离一个平面的带符号的距离函数，该平面是函数场的零势面。
Fig3.2表示MVS算法的重建步骤和中间或者最终几何形态类型，许多MVS算法集中于单个重建步骤，然而有些将多个步骤组合成操作管线，本表表达了大多数MVS算法/系统，除了一种算法-直接通过图像一致性体素构建mesh，通过体素融合方法[190，102]，在这个方法中，图像一致性体素替换了点云图或者深度图。
当然有许多过去开发的算法再这里没有列举出来，例如level-set方法，level-set曾经在MVS算法中非常流行，因为它能处理拓扑结构的变化[58]，典型的重建步骤是初始化模型然后进行优化，拓扑结构的初始化可能是不正确的，然而level-set不再被使用因为更好的初始化或者重建算法（见本章）已经被开发出来。高质量的模型和正确的拓扑结构能够直接通过图像一致性获取，因此就不需要优化过程。同样的早些时候许多算法基于visual hull初始化mesh形态，然而最新也不再使用，因为形状的提取过程通常需要人工手动提取，visual hull 不再是有效的近似或者对于有许多凹面的结构情况不再有效，更好的初始化重建技术发展也加速就有方法的淘汰。[注全自动的形态提取方法见47，49，50]。

![avatar](./mvs_pic/3-1.png)
*MVS算法可以采用输出场景表达进行分类，四种流行的表示方式是深度图、点云图、体素场和mesh面片，注意稠密的点云看起来像带纹理的mesh模型，虽然只是一些3d点云，重建出来的示例来自MVS中的state of art从上到下依次来自于[48] [74] [94] [93] *

***3D表达和应用 ***
表3.1总结了四种场景表示方法在三种流行应用中的可行性分析，3D重建的主要应用是在图形学中(可视化)，同时表格列出了两种不同的可视化应用。基于视图的纹理映射技术依赖于渲染相机视角改变图像的渲染，该技术产生沉浸式的可视化体验，由于渲染主要基于实时图像，并且能传递复杂的广度效果例如镜面高光或者透明半透明，这些都是很难去模拟的[54，68，170]，谷歌街景[81]是一个很好的基于视图纹理映射技术的例子，但是，为了避免渲染伪影，渲染摄影机必须靠近输入图像。渲染摄影机的运动范围严重受限于输入照片的覆盖范围。深度图表达方式对视图的纹理映射技术及其有效，因为它的几何形状可以优化渲染每一个透视图[127].天空的建模对于室外场景的可视化很有挑战，因为几何形状难以描述不容易重建，深度图为了达到更好的渲染效果可以为每个透视图生成几何代理，对Mesh、点云，体素来说并不容易，因为他们是独立于视图的。
另一方面，自由视点渲染运行在空间自由移动，对于导航和浏览目的的应用更友好，google地图就是很好的例子，然而渲染通常独立于视图并且缺少真实感。对于自由点渲染方法，mesh或者点云更合适，纹理映射的MVS mesh方法已经成功应用在城市户外可视化产品中[30，108，144]。基于点的渲染技术已经应用于计算机图形学中[83]，高质量的可视化点云或者深度图(也可以做点云处理[69,117,104])产生高质量的可视化结果。然而对于MVS生成的点云有很少的工作集中在基于点云的渲染方法，MVS点云常有噪点和重建出来的孔洞，渲染质量会严重降低。
最后的应用是几何操作。随着MVS技术的发展和重建的场景越来大，越来越复杂，几何操作功能越来越重要。为了完成一个场景的模型，处理多个MVS重建结果是必须的。对于这项任务mesh表示方式存在很大的挑战，因为通过合并和拆分来控制网格的拓扑结构很困难，所以会有几何操作方式。
在图3.2中，抛光体素（体积标量场）和mesh网格在图的底部。但是这可能不是每个MVS系统目标。 例如，如果依赖于视图的纹理映射
应用程序，应该简单地选择深度图重建算法。如果是自由视点渲染应用程序，则可以从图像进行点云重建，然后可以对应用程序使用基于点的渲染技术，而无需运行图中的任何其他步骤。 当然，高质量的多边形mesh网格模型通常是首选的场景表示，并且所有处理都归于图中的网格重建。

*** Evaluations ***

MVS研究人员进行了定量评估以验证MVS算法的准确性[165,176]。 Seitz, Curless, Diebel,
Scharstein和Szeliski在2006年为MVS定量评估奠定了基础[165]，该评估在具有低分辨率（640×480）图像的两个物体数据集上评估MVS算法，这些数据集是在具有一定照明的实验室环境中仔细获得的。此评估称为Middlebury MVS评估。虽然低分辨率图像的使用可能无法反映现代消费市场中高分辨率数码相机的存在，但它具有最小化校准误差影响的优点：更高的图像分辨率需要更精确和可重复的机械装置（例如机器人手臂）。几年后，Strecha，Hansen，Van Gool，Fua和Thoennessen发布了互补的MVS基准数据集和评估系统，重点关注室外场景和高分辨率输入图像，这反映了MVS研究的趋势和需求[176]。许多算法在重建精度方面令人印象深刻（例如，在640×480图像的20cm体积内0.5mm精度），并且还产生了引人注目的3D模型，包括本章中介绍的所有最优的算法。
一个缺失的评估是重建模型的视觉质量。Middlebury MVS 评估揭示了这样一个事实， 即纯几何量化指标并不总能反映模型的视觉质量。 换句话说，具有清晰视觉伪影的模型有时会获得更好的几何精度。 最近的MVS算法产生视觉上高质量的3D模型，不仅是几何精度[164,167]。 未来的MVS评估应该同时考虑几何精度和视觉质量。 
现在我们为四个输出场景表示提供MVS详细的重建算法细节。

### 3.1深度图重建

由于灵活性和可扩展性，深度图场景表示是最受欢迎的选择之一。 假设一个人被给予成千上万的图像和相机参数作为输入。 人们可以简单地为每个输入图像重建深度图，可能在找到要一起用于照片一致性评估的少量相邻图像之后。 通过将深度图视为3D点的2D阵列，可以将多个深度图视为合并的3D点云模型。 该处理简单并且可以容易地扩展到大量图像。

MVS中的深度图重建通常在狭窄的基线假设下进行，其公式与传统的两视图立体声相同[162]。该方法采用一组图像
摄像机参数，将有效深度范围离散为有限集深度值，然后重建参考图像的3D几何。
对于简单和紧凑的物体，均匀深度采样可能就足够了。
但是，对于复杂和大型场景，适当的采样方案是对于实现高速和高质量至关重要。研究人员提出了对样本深度的透视校正或对数参数化
值，详情参见论文[203,104,75]。然而，MVS深度图重建算法往往比它们的两个视图立体声对应物更简单，因为通常有一个
更多的图像，从而更多的冗余。换句话说，在MVS的上下文中，单个深度图的完整性并不重要只要合并的模型准确完整。
在本节的其余部分，我们将描述几个细节代表性的MVS深度图算法，然后再谈几个先进的技术。

#### 3.1.1 winner-takes-all depthmaps(赢者通吃)

假设给出一个需要计算深度的参考图像，一组相邻图像以及应该包含需要重建场景的深度值范围。一个简单的深度图重建算法是评估整个深度范围内的图像一致性值，每个像素独立选择图像一致性得分最高的深度值，这被称为“赢家通吃”方法，如图3.3所示。
其中NCC作为图像一致性测量方法，并且预计在正确的深度处具有最大值。Algorithm1中给出了完整的算法描述。除了具有最高图像一致性的深度值之外，该算法还经常评估置信度测量，使低置信度深度值在之后的模型合并步骤[106]中可以忽略或减小权重。这个简单的算法首先由Hernández和Schmitt [93]证明并且效果出奇的好。 该算法已经进行了各种改进，接下来我们将注意力转向更复杂的方法。

#### 3.1.2 Robust Photo-Consistency Depthmaps(鲁棒性)

虽然算法1运行得相当好，但总的来说并不能保证匹配窗口在物体表面上是唯一的。更大的窗口尺寸更可能导致匹配的唯一性，然而，对应的峰值区域将更大且不容易定位，降低了深度估计的准确性。遮挡和非朗伯光度效应如镜面反射高光也为照片一致性功能添加噪音。 因此，简单地使用式（2.3）中的平均值可能效果不佳（见图3.4）。Vogiatzis，Hernández，Torr和Cipolla[190]提出了一种强大的图像一致性功能来克服这些挑战。具体来说给出某像素的根据参考图像和每个临近的图像的计算出来图像一致性曲线，算法首先从所有照片一致性曲线中计算局部最大值。dk -- 深度值，Ck 对应的图像一致性数值的第kth个最大值，鲁棒图像一致性函数为：
********* func **********
W是核函数 -如高斯函数[190]， 作用如图Fig3.4所示，简单的平均值方法选择错误的深度作为全局最大值，而鲁棒的图像一致性成功地抑制了异常值。fig3.5说明噪声点是如何被该方法抑制的。另一种更简单但有效的方法是忽略低于某一阈值的光电一致性分数。Goesele，Curless，而Seitz只是计算成对照片一致性的平均值忽略低于某个阈值的值后得分[80]。这样的阈值处理是一种非常敏感的操作，结果严重依赖于参数选择，一般是NCC的光照一致性众所周知，在不同的输入中，它是非常强大和稳定的数据。因此常使用常数值阈值来计算NCC得分。采用类似的照片一致性功能处理点云重建框架，具体细节见3.2.1节。
Fig3.6 是鲁棒性算法的重建结果 by Goesele, Curless, and Seitz [80]顶行显示左侧的示例参考图像，以及两个不同的重建深度图右边深度置信度的阈值。深度估计当置信估计低于阈值时，丢弃像素。左深度图的阈值更严格（更高），因此，噪音较小但观察到更多的洞。请注意深度图通常通过转换估计的深度将其可视化为图像将值转换为有效的图像强度。然而，在该图中，深度图被可视化为阴影多边形模型，其通过a获得简单的体积融合技术[52]（参见第3.3节）。数据集由24个图像组成，他们重建了24个图像深度贴图，然后将它们合并为一个多边形模型相同的融合技术，其结果显示在底行。一个单个深度图非常嘈杂，包含很多洞，但合并后模型变得更清洁，并且展示出更少的重建孔。该输入图像数量对重建质量的影响是如图3.7所示。拥有超过300张图像，寺庙模型变得完整，而恐龙模型仍然有一些漏洞均匀的纹理，使照片一致性评估更多具有挑战性的。

#### 3.1.3 MRF 深度图(MRF Depthmaps)

尽管使用了如上一节所示*鲁棒图像一致性*函数，但在特殊情况下图像一致性曲线的峰值可能与实际深度不匹配。如存在严重遮挡的情况下，大多数情况下图像中可能不存在对应的匹配。这些问题的标准解法是：在相邻像素具有相似深度值的假设下强制使用空间一致性，其中马尔可夫随机场（MRF）对于求解该任务非常成功。 MRF深度图公式[120]可以被看作组合优化问题，其中输入深度值被离散化为有限的深度值范围集合。 然后问题是从标签集中向每个像素*p*设置一个深度标签*kp*，同时最小化以下损失函数

![avatar](./mvs_pic/formula3-2.png)

第一个求和公式是在图像所有像素上求和,第二个是在所有相邻像素上，相邻像素可以表示为*N*，相邻像素可以分为4-邻域和者8-邻域，前者是在水平、垂直相邻像素上；后者同时包含对角相邻像素。4邻域系统具有较少的交互项并且更简便，但可能受到更多离散化的影响。接下来讨论下unary potentials *phi(.)*和pairwise interaction potentials *psi(.,.)*

*** unary potentials ***
一元标签损失函数反应了图像一致性损失，它与图像一致性成反比。一元损失函数的定义各不相同。假如取值范围在[-1,1]的NCC作为图像一致性函数，一元损失可以定义为如下所示的线性截断损失函数：

![avatar](./mvs_pic/formula3-3.png)

式中：*τ<sub>u</sub>*为截断阈值。任意的鲁棒函数如:huber或cauchy损失函数也可以作为一元损失函数。

*** Pairwise Interaction Potentials ***
成对损失项
成对损失项强制使用空间正则化并与相邻像素的深度差异量成正比，以便使相邻像素具有相似的深度值。成对损失函数的定义也会有所不同，但下面给出一个简单的实现，作为截断线性损失函数，以避免惩罚深度不连续：

![avatar](./mvs_pic/formula3-4.png)

*** Optimization ***

式3.2虽然是一个NP问题但是也存在多种近似解，尤其是当pairwise项满足下式时[122]。

![avatar](./mvs_pic/formula3-5.png)

对于次模函数，最受欢迎的技术之一被称为alpha扩展[122,45,44]，它反复解决最大流量最小割算法以改进标签类别。
幸运的是，子模条件适用于许多标准成对项。更具体地说，作为距离度量*Ψ(α,α)*应为0，因为两个标签是相同的。剩下的条件为三角不等式：
![avatar](./mvs_pic/formula3-6.png)

平滑先验通常被定义为距离度量，并且满足上式的三角不等式^2。示例中的度量是线性的、截断线性或Cauchy(柯西)损失函数。但是，二次或Huber损失函数不是子模函数，因为二次函数不服从三角不等式。 请注意，与成对损失不同，unary potential函数没有限制，可以任意设定。MRF可以用来解决许多其他计算机视觉问题，有关MRF的更多细节将会在接下来的章节详细描述[114,179]。

[2]：子模块化优化是机器学习社区中的一个热门研究课题，其中子模块描述了一系列函数的数学性质。但是在计算机视觉中，通常使用子模块来描述多标记目标函数组合优化问题。 它们在数学上是等价的，但是以非常不同的方式来处理。

#### 3.1.4 Multiple Hypothesis MRF Depthmaps

上一节提到Campbell，Vogiatzis，Hernández和Cipolla扩展标准MRF用来改善结果[48]。而不是对于整个图像不假思索的使用离散的深度值作为可能的标签集，他们的算法从每个像素的图像一致性曲线中提取局部最大值，然后使用MRF公式为每个像素分配一个这样的局部最大值的深度。因此不同的像素具有不同的标签集。他们还使用“unknown(未知)”标签表示某些情况下无法正确估计深度值的情况。在这种情况下，他们承认这个像素点的深度值是未知的，因此不应对表面提供任何数值。这意味着返回的值都是准确的深度，该估计值具有高度的确定性。
该过程包括两个阶段：1）深度标签的提取;2）MRF优化用来分配赋值提取的深度标签。我们现在讨论算法的细节。

##### Depth Label Extraction

第一阶段是获取像素p在参考图像I<sub>ref</sub>中深度值的假设集。 在计算I<sub>ref</sub>和相邻图像的图像一致性曲线后，深度范围内的曲线图像，保留从所有曲线中得分最高的K个曲线的峰值{di（p）|i∈[1，K]}，图像一致性函数采用NCC算法。 如前所述，该算法的另一个关键特征是包含未知状态U，当没有足够的选择证据时。 因此对于每个像素，它们形成深度标签集{{d<sub>i</sub>(p)},U}。

#### MRF Optimization

深度标签分配被当做MRF优化问题，其中每个像素有最多(K + 1)个标签。 如果在深度标签提取阶段找到的峰数不足，标签数K则更少.对应于图像一致性函数中的峰值并相关深度d<sub>i</sub>(p)和得分C(p,d<sub>i</sub>(p))。 最终的状态是如前所述的未知状态U.
一元损失函数很简单。 我们希望对较低的匹配值的局部最大值增加惩罚项，因为它们更可能导致不正确的匹配。 他们采用指数函数的反函数将此分数映射到正损失函数[190]，  而常量惩罚项Φ<sub>U</sub>被强制用于未知状态像素,以避免给具有较差的图像一致性并且没有相邻pairwise项的像素分配深度值.

![avatar](./mvs_pic/formula3-7.png)

pairwise项强制使用进行空间正则化。有两个标签类型（深度值和Unkonwn状态）和成对损失在以下4(= 2×2)种情况下定义：

![avatar](./mvs_pic/formula3-8.png)

第一种情况，两个标签都有深度值，即损失函数只需计算(3.6)中的差异量。需要注意的是差异量通过深度值的平均值进行归一化，以使其与缩放相关性降低。第二和第三种情况是其中之一标签是Unknown状态，使用常量惩罚项是为了防止频繁切换深度标签和未知状态。最后一种情况是两个标签都是未知状态，为了保持空间一致性惩罚项被设置为0。
遗憾的是pairwise  cost在这个公式中并不是子模块，因为每个像素的深度标签是独立提取的，并且第i个标签的含义是不同的。例如，Ψ(d<sub>i</sub>(p)，d<sub>i</sub>(q))在标准MRF公式（3.6）中为0，因为d<sub>i</sub>(p)和d<sub>i</sub>(q)是像素无关的并且对应于相同的深度值。但是，在公式中事实并非如此,因此alpha扩展不适用.但是message passing(消息传递)算法，如循环信念传播（LBP）[204]和tree-reweighted message passing（TRW）[194]，这是MRF的其他流行的优化技术,特别是TRW已成功应用于解决许多计算机视觉问题包括深度图重建[123,179]，并用于工作中。

图3.8说明了图像一致性曲线和局部最大值的位置边界。请注意，遮挡边界处像素分配为未知标签（从顶部开始的第六个像素），其中为了分配正确的深度标签强制执行空间正则化，即使曲线的全局最大值对应于错误的深度（从上数第四个像素）。图3.9列出了更多的实验结果,其中包括重建过程中的中间结果用于评估。如图所示，单个深度图在Unknown(未知状态)标签和在ref参考图像中不可见的部分是一个空洞。然而，仅用高置信度区域的结果用于重建是很重要的,可以在融合步骤中以最小化噪声的存在。图3.9说明了该模型仅在两个有重叠的深度图的中变得接近完整。

![avatar](./mvs_pic/3-9.png)

#### 3.1.5 More Depthmap Reconstruction Algorithms

以上内容除了前面几节,已经提出了许多深度图重建算法。 本部分介绍了一些更重要的算法和技术文献

##### Real-Time Plane Sweeping Depthmap Reconstruction

深度图重建的计算量不是廉价的操作,图像一致性函数需要在图像的每个像素和每个假设深度的上进行评估。然而，Gallup, Frahm, Mordohai, Yang, and Pollefeys证明通过聪明地使用GPU可以实现实时[76]。该算法被称为“Plane Sweeping Stereo”，因为它扫描了一系列场景中的平行平面，通过平面将图像投影到平面上单应性，然后评估每个平面上的图像一致性。
每个像素的深度值由“赢者通吃”策略选择，算法中有两个关键特征。

![avatar](./mvs_pic/3-10.png)

首先，在算法方面，如图3.10的第二行所示，它沿多个方向扫描，这些方向是从场景中提取的，使扫描方向沿着将要重建的场景结构。为了评估照片图像的一致性，大多数算法假设表面相对于ref图像是互相平行的。相当于沿单个固定方向扫描平面。如图3.10的第一行所示，当场景表面不沿着平面方向，不同图像中的相关窗口在平面上不匹配。另一方面，当场景表面在平行的平面时，完全相同的3D表面区域投影到相关窗口，产生准确的照片一致性评估。每个扫描方向产生一个深度图，多个深度图合并产生最终结果（更多细节参见文章[76]）。该策略对于通常存在少数主导（例如，曼哈顿）方向的城市场景特别有效，稀疏的3D点云可以从SfM系统重建中获取。
第二个关键区别是高效的GPU实现图像重投影和照片一致性评估，实现实时表现。更具体地，将图像纹理重新投影到扫描平面上遵循平面单应性，这是标准渲染过程并且可以在GPU上有效地执行。后收集重新投影的纹理图像，照片一致性评估也可以在每个像素的GPU上执行。照片一致性功能在原始论文中使用的是增益校正的平方差的和（SSD）。系统在视频序列上进行了演示相同的相机在大致恒定的照明条件下每个序列，这是SSD仍然有效的原因之一使用更昂贵的功能，如NCC并不重要。

![avatar](./mvs_pic/3-11.png)

采用2.4GHzAMD双核处理器和NVidia GeForce 8800系列GPU以每秒30帧的速度处理512×384视频流。每个深度图计算使用7个图像和48个扫描平面，这仅需要24毫秒。在重建每帧深度图之后，系统具有将所有深度图合并到网格模型中。具体细节见他们的论文[76]，接下来我们在3.3节中将会介绍流行的融合技术。图3.11显示了以上算法对几个街道重建的结果。最大的数据集包括170000帧，
该系统通过简单的计算产生了近300亿（≈512×384×170,000）个3D点
，计算忽略高冗余和漏洞重建，其规模远远大于当时出版的对应（相关）方法（2007年）。

##### Second Order Smoothness

MRF成功用于各种深度图重建算法以及许多其他计算机视觉任务都可以离散成相对较少数量的标签。典型的平滑度先验作用于一对像素，并试图使两个像素的深度差异最小化。 在深度图重建框架中,该先验倾向于前表面平行的平面,也就是说所有的表面有相同的深度值.然而在现实场景中,大多数表面与ref图像并不平行,当假设不成立的时候,先验知识可能会导致重建误差见图3.12.

![avatar](./mvs_pic/3-12.png)

Woodford, Torr, Reid, and Fitzgibbon 提出了一个立体算法,仍然采用MRF方法,但引入了在三个团(即三个像素)的二阶平滑先验,强制执行分段平面表面 [196]。更具体地说,给定三个相邻的像素 (p, q, r) 惩罚项 [d<sub>p</sub> + d<sub>r</sub> - 2d<sub>q</sub>] 作为平滑损失函数,它是一个二阶导数的有限近似,
当第一阶导数是常量时损失函数为0,即当表面是分段平面。triple cliques的引入使优化变得复杂(至少成本函数不是子函数)需要更复杂的优化算法需要来解决该问题。优化算法的详细信息参考他们的论文[196]
二阶平滑先验的效果和真实情况如图3.12所示。 在顶部合成示例中，大多数结构是分段平面,并且通过标准方法重建（即1阶先验）效果不理想，产生了分段的平行表面。 他们的算法成功地按预期重建了大多数分段平面。 底部例子中大多数真实结构是弯曲的而不是分段平面。 尽管如此，他们的重建结果要多得多比标准方法准确，因为分段平面平滑先验更灵活，更紧密地贴合弯曲表面与平行光滑先验相比。 标准方法在许多地方都存在阶梯状外壳伪影。

### 3.2 Point-cloud Reconstruction

    我们在上一节中已经看到，多个深度图是一种非常流行的场景表示方式并且它可以扩展到大的场景，因为核心重建任务仍然是单个深度图估计。虽然深度图足以满足大多数应用，如场景分析和可视化，主要问题是如何将它们合成一个全局 3D 模型。有许多方法可以合并多个深度图 [52、76、94、142、153、207]。方法的有效性取决于深度图中存在的噪声类型。密集采样的图像可以显着提高重建质量，尤其是在具有挑战性的地方例如薄板结构和深度不连续的地方[117]。然而，深度图质量往往会在深度不连续和遮挡边界处显着下降。这么低质量 3D 估计需要在过程中被过滤掉或抑制模型合并。同样，在一个大场景中，相同的表面区域在许多相机中都可以看到，其中一些可能很远。这深度图估计的准确性通常与到地表的距离，以及来自远处相机的深度图估计需要再次过滤掉或抑制，即使在不存在的情况下深度不连续性或遮挡[65, 69]。研究人员探索了在执行时同时估计多个深度图的方法，同时在多个图像之间强制几何一致性[121、174、177]。然而，这些方法往往会使优化问题变得非常大计算成本高。

    基于点云或补丁的表面表示克服了这些困难，因为他们通过重建单个点云 3D 模型使用所有输入图像，同时保持简单模型的优势合并和拆分等操作。 请注意，一个 3D 点与表面法线估计或局部区域支持称为定向点或补丁。

点云重建算法的一个共同特点是他们利用空间一致性假设并成长或者在重建过程中扩展场景表面的点云，而不是独立地重建每个点。这种扩张或区域增长的想法在 MVS 中并不是独一无二的，并已在许多其他计算机视觉任务中得到利用，例如作为特征匹配、分割和识别[149,126,60]。在在 MVS 上下文中，Lhuillier 和 Quan 提出了一项早期工作，其中补丁以贪婪的方式扩展[132]。哈贝克和科贝尔特还提出了一种类似的算法，将补丁迭代扩展为重建一个对象[85]。类似的想法将在以后被利用用于深度图重建的双视图立体设置。尤其，“PatchMatch Stereo”是一种成功的算法 [40]，它随机初始化深度值，然后根据局部传播和随机搜索策略对其进行细化。他们的灵感来源来了来自最初开发的“PatchMatch”算法[34]用于一般图像匹配。

 本文重点介绍 Furukawa 和 Ponce [74] 3 的基于点的重建工作。该算法还遵循贪婪扩张的方法，但一个关键的区别是它在通过特征匹配重建补丁的初始种子之后，在扩展和过滤步骤之间进行迭代。 过滤步骤分析所有视图中补丁的一致性并删除错误重建的补丁。 我们将首先解释几个基本的构建算法块，然后提供三个处理的详细信息步骤，即初始特征匹配、扩展和过滤。 笔记本文描述了该算法的简化版本，以简明扼要，完整的细节参见他们的期刊论文[74]。

#### 3.2.1 Key Elements

他们算法的输出是整个场景的一组补丁，本节解释了他们基于图像的数据结构来跟踪重建的补丁，以及直接估计深度和表面法线的补丁模型/优化技术。

##### Patch Model

    补丁 p 本质上是曲面的局部切平面近似，其几何形状由其中心 c(p) 和单位法线确定向量 n(p)。因此，虽然只有一个典型的光一致性函数将位置作为评估的输入，可以扩展函数将位置和表面法线作为输入。通过使用简单地评估照片一致性函数patch 作为代理几何体来采样像素颜色（参见图 3.13）。虽然 NCC 是许多其他算法的核心指标，但它们适用于NCC 评分的稳健功能，以使其光一致性对异常信号具有稳健性（参见第 3.1.2 节，了解类似的稳健光一致性技术）。让 C 表示 NCC 分数，然后是稳健的光一致性定义为 -C /(3C +1)，其中 C = min(τ, 1-C)。τ 是截断阈值，设置在 0.4 左右。坚固的形状功能如图 3.14 所示。

    定义了补丁的光度一致性度量作为其位置和法线的函数，重建一个补丁简单地通过最大化照片一致性函数来实现尊重这些参数。乍一看，函数有五个参数需要优化，因为位置由三个参数组成法线由两个参数组成。但是，补丁应该在优化过程中不要在曲面上切向移动，其中只有它的应优化位置参数的垂直偏移。这垂直方向取决于面片法线，这也是优化的。因此，在实践中，垂直方向是固定的在整个优化过程中，其中一个参数用于位置和法线的两个参数通过标准非线性优化最小二乘技术。

##### Image-based Data Structure

基于补丁的表面表示的主要优点是灵活性。 但是，由于缺乏连接信息，它是仅仅搜索或访问相邻的补丁并不容易，然后强制执行例如，正则化。 在他们的方法中，图像投影可见图像中的重建补丁用于帮助执行这些任务。 具体来说，它们与每个图像 Ii 相关联β1 × β1 像素单元 Ci(x, y) 的网格，如图 3.15 所示（β1 = 2 在它们的实验）。 给定一个补丁 p 及其可见图像 V (p)，即作为重建过程的一部分，他们将 p 投影到V（p）中的每个图像以识别相应的单元格。 然后，每个单元格Ci(x, y) 记住投射到其中的一组补丁 Qi(x, y)。可以通过查看相邻单元格来收集相邻的补丁可见图像

##### 3.2.2 Algorithm

他们基于补丁的 MVS 算法尝试重建至少一个每个图像单元 Ci(x, y) 中的补丁。 它分为三个步骤：（1）初始特征匹配，（2）<mark>补丁</mark>扩展，和（3）补丁过滤。初始特征匹配步骤的目的是生成一个稀疏的一组补丁（可能包含一些误报）。 扩展和过滤步骤迭代 n 次（通常 n = 3）到使补丁密集并删除错误的匹配。 三个步骤以下各节详细介绍。

##### Initial Feature Matching

算法的第一步是检测blob和corner特征在每个图像中使用高斯差分（DoG）和哈里斯算子[178]。 考虑一个图像 Ii，其光学中心表示为O(II)。 对于在 Ii 中检测到的每个特征 f，他们在其他图像中收集相同类型（Harris 或 DoG）的特征 f 的集合 F距对应极线的两个像素内，并进行三角测量与对 (f, f ) 关联的 3D 点。 然后，他们考虑这些点按与 O(Ii) 的距离递增的顺序作为潜在补丁中心，并尝试从点生成一个补丁一个，直到他们使用以下程序成功。 给定一对
特征 (f, f )，他们首先构造一个候选补丁 p ，其中心为c(p) 和法线向量 n(p) 初始化为通过基于视角差异收集固定数量（通常为五个）的附近视图来初始化可见图像集 V (p)。然后，应用补丁优化程序来细化这些参数。 优化后，V(p) 包含与 Ii 的成对照片一致性大于某个阈值的图像。 这如果 |V (p)|，则补丁保持成功 至少是 γv，通常设置为到 3. 根据经验，这种启发式方法已被证明在选择以适度的计算成本大部分正确的匹配。 图 3.16 给出了该步骤的总体算法描述。 当然，这个相对简单的程序可能并不完美并且会产生错误，但过滤步骤将处理此类错误

##### Expansion

扩展步骤的目标是重建至少一个补丁每个图像单元 Ci(x, y) 重复获取现有的补丁和在附近的空白处生成新的。更具体地说，给定一个补丁 p，他们首先识别一组相邻的图像单元 Cells(p)
尚不包含任何补丁的：细胞(p) = {Ci(x , y )| (3.11)
p ∈ Qi(x, y), Qi(x, y) = ∅, |x − x | + |y - y | = 1 (3.12) }。
对于 Cells(p) 中的每个收集到的图像单元 Ci(x, y)，执行以下扩展过程以生成新的补丁 p。他们首先用对应的 p 值初始化 n(p ) 和 V (p )。 c(p ) 是，在转弯，初始化为观察光线通过的点
Ci(x, y) 的中心与包含补丁 p 的平面相交。然后，他们通过第 3.2.1 节中描述的优化过程细化 c(p) 和 n(p)。他们从 V (p) 中删除图像，其平均值V (p) 中剩余图像的成对照片一致性得分为
小于一个阈值。如果他们的平均值，他们还会将图像添加到 V (p )成对照片一致性分数高于阈值。最后，如果|V(p)| ≥ γv，他们认为补丁成功并更新 Qi(x, y)因为它的可见图像。该过程重复，直到扩展过程从已重建的每个补丁执行。整体算法描述如图 3.17 所示。

##### Filtering

扩展步骤是贪婪的，完全依赖于照片的一致性重建补丁的措施，其中很难避免生成任何错误的补丁。在算法的最后一步，以下两个过滤器用于删除错误的补丁。首先过滤器依赖于可见性一致性。如果补丁 p 和 p 沿法线的距离小于阈值，则让我们定义补丁 p 和 p 是邻居：
|(c(p) − c(p)) · n(p)| + |(c(p) - c(p)) · n(p)| < γd。 (3.13)
γd 是允许的垂直偏移量的上限两个补丁。令 U(p) 表示与当前可见性信息不一致的补丁 p 的集合——即 p 和 p 不邻居，但存储在其中一个图像的同一单元格中，其中 p可见（图 3.18）。然后，如果满足以下条件，则将 p 作为异常值过滤掉不等式成立
|V (p)|(1 - C(p)) <pi∈U(p) 1 - C(pi)。 (3.14)
C(p) 是 p 的平均成对照片一致性分数。直觉上，当 p 是异常值时，1−C(p) 和 |V (p)|预计很小，并且 p 很可能会被删除。在第二个过滤器中，我们强制执行弱正则化形式：对于每个补丁 p，我们收集位于的补丁在 V (p) 的所有图像中它自己和相邻的单元格中。如果在该集合中与 p（等式 3.13）相邻的块的比例低于0.25，p 作为异常值被移除

#### 3.2.3 Reconstruction Results

图 3.19 显示了一个示例输入图像、图像分辨率和每个数据集的输入图像数量。 基于补丁的表示是灵活的，可以处理像数据集这样的“对象”（图 3.19 的第一行），其中摄像机围绕着一个对象，也可以处理像数据集这样的“场景”，相机被场景包围的地方。 他们重建的补丁如图 3.20 所示。 请注意，补丁很密集，看起来像表面模型，但仅仅是点云。 该图说明重建的补丁没有噪声并显示出鲁棒性尽管补丁是独立重建的没有明确的正则化。 图 3.20 的下半部分显示从补丁转换的多边形表面模型，它验证了重建补丁的几何精度（参见第 3.3 节用于表面网格技术）

### 3.3 Volumetric data fusion

### 3.4 MVS Mesh Refinement
